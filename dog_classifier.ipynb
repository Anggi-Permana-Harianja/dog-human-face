{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "import random\n",
    "random.seed(8675309)\n",
    "\n",
    "human_files = np.array(glob(\"lfw/*/*\"))\n",
    "random.shuffle(human_files)\n",
    "\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "img = cv2.imread(human_files[5])\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "ResNet50_model = ResNet50(weights='imagenet')\n",
    "\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))\n",
    "\n",
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151)) \n",
    "\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1, \n",
    "    horizontal_flip=True) \n",
    "\n",
    "datagen.fit(train_tensors)\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(filters=16, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.bestaugmented.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensors, valid_targets), \n",
    "                    steps_per_epoch=train_tensors.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
    "batch_size = 20\n",
    "epochs = 5\n",
    "\n",
    "model.fit_generator(datagen.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    validation_data=(valid_tensors, valid_targets), \n",
    "                    steps_per_epoch=train_tensors.shape[0] // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "bottleneck_features = np.load('bottleneck_features/DogResnet50Data.npz')\n",
    "train_ResNet50 = bottleneck_features['train']\n",
    "valid_ResNet50 = bottleneck_features['valid']\n",
    "test_ResNet50 = bottleneck_features['test']\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "ResNet_model = Sequential()\n",
    "ResNet_model.add(GlobalAveragePooling2D(input_shape=train_ResNet50.shape[1:]))\n",
    "ResNet_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "ResNet_model.summary()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best_adamax.ResNet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "ResNet_model.fit(train_ResNet50, train_targets, \n",
    "          validation_data=(valid_ResNet50, valid_targets),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "opt = Adamax(lr=0.0002)\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "ResNet_model.fit(train_ResNet50, train_targets, \n",
    "          validation_data=(valid_ResNet50, valid_targets),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)\n",
    "ResNet_model.load_weights('saved_models/weights.best_adamax.ResNet50.hdf5')\n",
    "\n",
    "from extract_bottleneck_features import *\n",
    "\n",
    "def ResNet50_predict_breed(img_path):\n",
    "    bottleneck_feature = extract_Resnet50(path_to_tensor(img_path))\n",
    "    predicted_vector = ResNet_model.predict(bottleneck_feature)\n",
    "    breed = dog_names[np.argmax(predicted_vector)]\n",
    "    img = cv2.imread(img_path)\n",
    "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgplot = plt.imshow(cv_rgb)\n",
    "    if dog_detector(img_path) == True:\n",
    "        return print(\"The breed of dog is a {}\".format(breed))\n",
    "    else:\n",
    "        return print(\"If this person were a dog, the breed would be a {}\".format(breed))\n",
    "\n",
    "    def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151)) \n",
    "\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0\n",
    "\n",
    "def predict_breed(img_path):\n",
    "    isDog = dog_detector(img_path)\n",
    "    isPerson = face_detector(img_path)\n",
    "    if isDog:\n",
    "        print(\"Detected a dog\")\n",
    "        breed = ResNet50_predict_breed(img_path)\n",
    "        return breed\n",
    "    if isPerson:\n",
    "        print(\"Detected a human face\")\n",
    "        breed = ResNet50_predict_breed(img_path)\n",
    "        return breed\n",
    "    else:\n",
    "        print(\"No human face or dog detected\")\n",
    "        img = cv2.imread(img_path)\n",
    "        cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        imgplot = plt.imshow(cv_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_breed('images/IMG_001.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
